{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPDj6HAwd/ZkhbXvgROborM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielahernandez29/Curso-IA/blob/main/Multicapa/Predicci%C3%B3n_de_combustible.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQYKaCTEqTvK"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Este programa nos ayudará a predecir el consumo de combustible \"\"\"\n",
        "\n",
        "# Se ocupo ucimlrepo: para obtener el conjunto de datos de consumo de combustible. pandas: para manipulación y análisis de datos. tensorflow y keras: para construir y entrenar la red neuronal. numpy: para operaciones numéricas.\n",
        "\n",
        "from ucimlrepo import fetch_ucirepo #inastalado via pip\n",
        "\n",
        "# Cargar el conjunto de datos de consumo de combustible\n",
        "auto_mpg = fetch_ucirepo(id=9)\n",
        "\n",
        "# Exploramos nuestros datos\n",
        "X = auto_mpg.data.features\n",
        "\n",
        "y = auto_mpg.data.targets\n",
        "\n",
        "print(X.head())\n",
        "\n",
        "print(y.head())\n",
        "\n",
        "X.info()\n",
        "y.info()\n",
        "\n",
        "# Las siguientes lineas de codigo borran las filas con valores faltantes\n",
        "import pandas as pd\n",
        "df = pd.concat([X, y], axis=1).dropna()\n",
        "\n",
        "# Verificamos que no haya valores faltantes\n",
        "df.info()\n",
        "\n",
        "# Definimos X e y\n",
        "X = df.drop('mpg', axis=1)\n",
        "y = df['mpg']\n",
        "\n",
        "# dividimos los datos en conjuntos de entrenamiento y prueba\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2, random_state=1\n",
        ")\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "# Escalamos las características para mejorar el rendimiento del modelo\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Construimos la red neuronal multicapa\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Definir el modelo\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compilar el modelo  Adam y una tasa de aprendizaje personalizada\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Tasa de aprendizaje\n",
        "learning_rate = 0.001\n",
        "adam_optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=adam_optimizer,\n",
        "    loss='mean_squared_error',\n",
        "    metrics=['root_mean_squared_error'],\n",
        ")\n",
        "\n",
        "# Entrenamos el modelo\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=5, batch_size=1,\n",
        "    validation_data=(X_test, y_test)\n",
        ")\n",
        "\n",
        "# Graficamos la función de pérdida\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.plot(history.history['loss'], label='Pérdida de entrenamiento')\n",
        "plt.plot(history.history['val_loss'], label='Pérdida de validación')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.legend()\n",
        "plt.title('Función de pérdida durante el entrenamiento')\n",
        "plt.show()\n",
        "\n",
        "# Evaluamos el modelo en el conjunto de prueba\n",
        "test_loss, test_mae = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test Mean Absolute Error: {test_mae:.2f}')\n",
        "\n",
        "# Comparamos las predicciones con los valores reales\n",
        "predictions = model.predict(X_test)\n",
        "comparison = pd.DataFrame({'Actual': y_test, 'Predicted': predictions.flatten()})\n",
        "print(comparison.head())\n",
        "\n",
        "# Calculamos métricas adicionales para evaluar el rendimiento del modelo\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "r2 = r2_score(y_test, predictions)\n",
        "print(f'R²: {r2}')\n",
        "\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(f'MSE: {mse}')"
      ]
    }
  ]
}