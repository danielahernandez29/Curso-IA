{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAyngpOBcQ/ayFVbqYG5iL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielahernandez29/Curso-IA/blob/main/Multicapa/Popularidad_de_una_canci%C3%B3n.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBlovm4-oadU"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Regresión con Red Neuronal para predecir Popularidad de Canciones\n",
        "Usamos Keras para predecir un valor numérico (popularidad).\n",
        "\"\"\"\n",
        "\n",
        "import pandas as pd # Para manejar los datos.\n",
        "\n",
        "# Cargar el conjunto de datos desde una URL\n",
        "url = \"https://raw.githubusercontent.com/mevangelista-alvarado/datasets/refs/heads/main/spotify_songs.csv\"\n",
        "# Cargo el dataset de Spotify.\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# Seleccionar características\n",
        "features = [\n",
        "    'danceability', 'energy', 'key', 'loudness',\n",
        "    'mode', 'speechiness', 'acousticness', 'instrumentalness',\n",
        "    'liveness', 'valence', 'tempo', 'duration_ms',\n",
        "]\n",
        "X = df[features].values # Mis variables de entrada.\n",
        "\n",
        "\n",
        "y = df['popularity'].values # Mi variable a predecir.\n",
        "\n",
        "# Dividimos los datos en conjuntos de entrenamiento y prueba\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Divido 80% (train) y 20% (test).\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Escalamos las características para mejorar el rendimiento del modelo\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Escalo los datos\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Definimos nuestra red neuronal multicapa\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='linear')\n",
        "])\n",
        "\n",
        "# Ocupamos Adam con una tasa de aprendizaje personalizada\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Tasa de aprendizaje estándar.\n",
        "learning_rate = 0.001\n",
        "adam_optimizer = Adam(learning_rate=learning_rate)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=adam_optimizer,\n",
        "    loss='mse',\n",
        "    metrics=['mae'],\n",
        ")\n",
        "\n",
        "# Entrenamos el modelo\n",
        "# Entreno por 50 épocas\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    validation_split=0.2,\n",
        "    epochs=50,\n",
        "    batch_size=50,\n",
        ")\n",
        "\n",
        "# Graficamos la función de pérdida\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Grafico la pérdida\n",
        "plt.plot(history.history['loss'], label='Pérdida de entrenamiento')\n",
        "plt.plot(history.history['val_loss'], label='Pérdida de validación')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Pérdida')\n",
        "plt.legend()\n",
        "plt.title('Función de pérdida durante el entrenamiento')\n",
        "plt.show()\n",
        "\n",
        "# Evaluamos el modelo en el conjunto de prueba\n",
        "loss, mae = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"MAE en el conjunto test: {mae}\") # Mi error promedio absoluto.\n",
        "\n",
        "# Predecimos y comparamos con los valores reales\n",
        "import pandas as pd\n",
        "\n",
        "# Hago las predicciones y las comparo con los valores reales.\n",
        "predictions = model.predict(X_test).flatten()\n",
        "comparison = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})\n",
        "print(comparison.head())\n",
        "\n",
        "# seleccionamos una canción para predecir su popularidad\n",
        "nombre_cancion = \"Beso\"\n",
        "\n",
        "# Busco un ejemplo específico para predecir.\n",
        "canciones_df = df[df['track_name'].str.contains(nombre_cancion, case=False, na=False)]\n",
        "\n",
        "print(f\"Canciones encontradas:\")\n",
        "canciones_df[['track_name', 'artists', 'album_name']].head()\n",
        "\n",
        "# indice a selecionar\n",
        "i = 0\n",
        "cancion = canciones_df.iloc[i]\n",
        "\n",
        "X_input = cancion[features].values.reshape(1, -1)\n",
        "X_input = scaler.transform(X_input)\n",
        "\n",
        "# Predigo la popularidad de esa canción.\n",
        "prediccion = model.predict(X_input)[0][0]\n",
        "print(f\"Canción: {cancion['track_name']} - {cancion['artists']}\")\n",
        "print(f\"Popularidad real: {cancion['popularity']}\")\n",
        "print(f\"Predicción: {prediccion:.2f}\")\n",
        "\n",
        "# Calculamos métricas adicionales para evaluar el rendimiento del modelo\n",
        "from sklearn.metrics import r2_score, mean_squared_error\n",
        "\n",
        "# Calculo el R² y el MSE para tener más métricas.\n",
        "r2 = r2_score(y_test, predictions)\n",
        "print(f'R²: {r2}')\n",
        "\n",
        "mse = mean_squared_error(y_test, predictions)\n",
        "print(f'MSE: {mse}')"
      ]
    }
  ]
}